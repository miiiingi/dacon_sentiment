{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dacon_sentimental analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDs1VHEvpajIpId8etSuQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miiiingi/dacon_sentiment/blob/main/dacon_sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7hwyVFOIFs-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b139a58b-bd82-466e-efc1-01192d72ec0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "my_folder = '/gdrive/MyDrive/ColabNotebooks/dacon_senti/dataset/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install konlpy\n",
        "from konlpy.tag import Mecab\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from torchtext.legacy import data, datasets\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "ctYxYX8XGDop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92d2e2f-f7c3-4b1d-b56d-6bcdb28d3ddd"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext - Field 정의"
      ],
      "metadata": {
        "id": "sTuFGseES5oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "ID = data.Field(use_vocab=False, sequential=False, batch_first= True)\n",
        "TEXT = data.Field(use_vocab = True, tokenize=okt.morphs, sequential= True, batch_first = True)\n",
        "LABEL = data.Field(use_vocab= False, sequential= False, is_target=True, batch_first= True)\n",
        "fields = [('id', ID), ('document',TEXT), ('label',LABEL)]"
      ],
      "metadata": {
        "id": "eJmv_1LMRmq9"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext - 데이터셋 불러와서 정의"
      ],
      "metadata": {
        "id": "k48eaLrAS_Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                            path = f'{my_folder}/',\n",
        "                            train = 'train.csv',\n",
        "                            test = 'test.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields,\n",
        "                            skip_header = True,\n",
        ")\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(722), split_ratio = 0.5)"
      ],
      "metadata": {
        "id": "d28sGlSZOfbT"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext - 단어 집합 만들기"
      ],
      "metadata": {
        "id": "1sDy8pfLTOXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, min_freq=5) # 단어 집합 생성\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "CrRJHNBdESTd"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext - 배치화 시키기"
      ],
      "metadata": {
        "id": "-tUAImEsUFIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (train_data, valid_data, test_data), batch_size=32, sort_key = lambda x: len(x.document), sort_within_batch = True,\n",
        "        shuffle=True, repeat=False)"
      ],
      "metadata": {
        "id": "aBGCjdvyIxiT"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU Model 정의"
      ],
      "metadata": {
        "id": "5pOhHmRMU_3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn as nn \n",
        "import torch.nn.functional as F\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers * 2,\n",
        "                          batch_first=True,\n",
        "                          bidirectional = True)\n",
        "        self.out = nn.Linear(self.hidden_dim * 2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        # h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\n",
        "        x, _ = self.gru(x)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
        "        h_t = x[:,-1,:] # (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "metadata": {
        "id": "ldD8b2O8UTJ1"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GRU(1, 256, len(TEXT.vocab), 128, 2, 0.5).to(DEVICE)\n",
        "# model = GRU(1, 256, len(TEXT.vocab), 128, 2, 0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "giqPHsMPVS5p"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "0vjeZhRHgTnp"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "32uYA2hzaH_w"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = None\n",
        "for e in tqdm(range(300)):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e+1, val_loss, val_accuracy))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), f'{my_folder}/snapshot/sentiment.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr4o2MwHZ3SG",
        "outputId": "32d0fb47-6aa0-4bb4-fa6f-6a01b987edac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/300 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VcRzc9RgaVfI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}