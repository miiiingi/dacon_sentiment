{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miiiingi/dacon_sentiment/blob/main/dacon_sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hwyVFOIFs-4",
        "outputId": "fc5f1f29-728a-4c0d-dc11-57dbefb9d44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "my_folder = '/gdrive/MyDrive/ColabNotebooks/dacon_senti/dataset/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctYxYX8XGDop",
        "outputId": "aea8f8bb-cacc-4302-ce53-e4cc3497e2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install konlpy\n",
        "from konlpy.tag import Mecab\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from torchtext.legacy import data, datasets\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTuFGseES5oO"
      },
      "source": [
        "Torchtext - Field 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eJmv_1LMRmq9"
      },
      "outputs": [],
      "source": [
        "okt = Okt()\n",
        "ID = data.Field(use_vocab=False, sequential=False, batch_first= True)\n",
        "TEXT = data.Field(use_vocab = True, tokenize=okt.morphs, sequential= True, batch_first = True)\n",
        "LABEL = data.Field(use_vocab= False, sequential= False, is_target=True, batch_first= True)\n",
        "fields = [('id', ID), ('document',TEXT), ('label',LABEL)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k48eaLrAS_Lr"
      },
      "source": [
        "Torchtext - 데이터셋 불러와서 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d28sGlSZOfbT"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "                            path = f'{my_folder}/',\n",
        "                            train = 'train.csv',\n",
        "                            test = 'test.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields,\n",
        "                            skip_header = True,\n",
        ")\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(722), split_ratio = 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sDy8pfLTOXY"
      },
      "source": [
        "Torchtext - 단어 집합 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrRJHNBdESTd"
      },
      "outputs": [],
      "source": [
        "TEXT.build_vocab(train_data, min_freq=5) # 단어 집합 생성\n",
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tUAImEsUFIB"
      },
      "source": [
        "Torchtext - 배치화 시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aBGCjdvyIxiT"
      },
      "outputs": [],
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "        (train_data, valid_data, test_data), batch_size=32, sort_key = lambda x: len(x.document), sort_within_batch = True,\n",
        "        shuffle=True, repeat=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOhHmRMU_3G"
      },
      "source": [
        "GRU Model 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ldD8b2O8UTJ1"
      },
      "outputs": [],
      "source": [
        "from torch import nn as nn \n",
        "import torch.nn.functional as F\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers * 2,\n",
        "                          batch_first=True,\n",
        "                          bidirectional = True)\n",
        "        self.out = nn.Linear(self.hidden_dim * 2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        # h_0 = self._init_state(batch_size=x.size(0)) # 첫번째 히든 스테이트를 0벡터로 초기화\n",
        "        x, _ = self.gru(x)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
        "        h_t = x[:,-1,:] # (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n",
        "        self.dropout(h_t)\n",
        "        logit = self.out(h_t)  # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "giqPHsMPVS5p"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GRU(1, 256, len(TEXT.vocab), 128, 2, 0.5).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0vjeZhRHgTnp"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train()\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "32uYA2hzaH_w"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.document.to(DEVICE), batch.label.to(DEVICE)\n",
        "        logit = model(x)\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item()\n",
        "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr4o2MwHZ3SG",
        "outputId": "e9ad6831-ad40-4b58-d81e-620be9665d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/300 [00:07<37:45,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] val loss :  0.59 | val accuracy : 72.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/300 [00:15<38:05,  7.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 2] val loss :  0.50 | val accuracy : 77.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/300 [00:22<37:58,  7.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 3] val loss :  0.52 | val accuracy : 77.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 4/300 [00:30<37:35,  7.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 4] val loss :  0.53 | val accuracy : 75.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 5/300 [00:38<37:21,  7.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 5] val loss :  0.58 | val accuracy : 76.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 6/300 [00:45<37:09,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 6] val loss :  0.55 | val accuracy : 77.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 7/300 [00:53<36:52,  7.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 7] val loss :  0.56 | val accuracy : 77.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 8/300 [01:00<36:53,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 8] val loss :  0.58 | val accuracy : 77.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 9/300 [01:08<36:53,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 9] val loss :  0.62 | val accuracy : 78.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 10/300 [01:16<36:51,  7.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 10] val loss :  0.77 | val accuracy : 74.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 11/300 [01:23<36:33,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 11] val loss :  0.67 | val accuracy : 78.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 12/300 [01:31<36:22,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 12] val loss :  0.85 | val accuracy : 76.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 13/300 [01:38<36:01,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 13] val loss :  0.73 | val accuracy : 77.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 14/300 [01:46<35:48,  7.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 14] val loss :  0.77 | val accuracy : 78.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 15/300 [01:53<35:39,  7.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 15] val loss :  0.80 | val accuracy : 77.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 16/300 [02:01<35:29,  7.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 16] val loss :  0.92 | val accuracy : 77.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 17/300 [02:08<35:27,  7.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 17] val loss :  0.99 | val accuracy : 78.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 18/300 [02:16<35:28,  7.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 18] val loss :  1.05 | val accuracy : 77.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 19/300 [02:23<35:19,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 19] val loss :  1.01 | val accuracy : 77.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 20/300 [02:31<35:06,  7.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 20] val loss :  1.10 | val accuracy : 78.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 21/300 [02:38<34:56,  7.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 21] val loss :  1.22 | val accuracy : 77.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 22/300 [02:46<34:58,  7.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 22] val loss :  1.24 | val accuracy : 78.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 23/300 [02:53<34:44,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 23] val loss :  1.12 | val accuracy : 77.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 24/300 [03:01<34:37,  7.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 24] val loss :  1.05 | val accuracy : 77.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 25/300 [03:08<34:35,  7.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 25] val loss :  1.13 | val accuracy : 77.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 26/300 [03:16<34:34,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 26] val loss :  1.28 | val accuracy : 77.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 27/300 [03:24<34:30,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 27] val loss :  1.34 | val accuracy : 77.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 28/300 [03:31<34:24,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 28] val loss :  1.35 | val accuracy : 77.52\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = None\n",
        "for e in tqdm(range(300)):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e+1, val_loss, val_accuracy))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"/gdrive/MyDrive/ColabNotebooks/dacon_senti/snapshot\"):\n",
        "            os.makedirs(\"/gdrive/MyDrive/ColabNotebooks/dacon_senti/snapshot\")\n",
        "        torch.save(model.state_dict(), f'/gdrive/MyDrive/ColabNotebooks/dacon_senti/snapshot/sentiment.pt')\n",
        "        best_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcRzc9RgaVfI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dacon_sentimental analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+gpq2KWrUUaykjIxogBhg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}